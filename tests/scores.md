-Qwen2.5-7B:
    -CustomTextSplitter:
        -chunk_size=250:
            {'cosine': 0.6571318442977517, 'bleu': 0.10471043535717553, 'rouge': 0.29339400067408156}
        -chunk_size=300:
            {'cosine': 0.6609497871944214, 'bleu': 0.17479544650985124, 'rouge': 0.3516868701621148}
    -TokenTextSplitter:
        -chunk_size=512, chunk_overlap=256:
            {'cosine': 0.4944883005311742, 'bleu': 0.0946342546424519, 'rouge': 0.23625800685237597}
        -chunk_size=512, chunk_overlap=0:
            {'cosine': 0.49887321624457426, 'bleu': 0.0946510854760713, 'rouge': 0.23015873015873015}
    -RecursiveCharacterTextSplitter:
        -chunk_size=300, chunk_overlap=150:
            {'cosine': 0.6237685630967321, 'bleu': 0.3084662755548556, 'rouge': 0.2852409638554217}
        -chunk_size=300, chunk_overlap=0:
            {'cosine': 0.659398099974317, 'bleu': 0.12068980618343653, 'rouge': 0.3124620060790273}

В качестве метрик были использованы: косинусное сходство эмбеддингов, BLEU и ROUGE:
- Косинусное сходство эмбеддингов позволяет определить степень сходства ответа, данного моделью, и образцового ответа. Метрика придаёт меньшее значение буквальному сходсту (повторяющиеся слова, цепочки слов),
и большее - смысловому. Точность метрики зависит от качества модели, создающей эмбеддинги.
- BLEU считает количество совпадающих n-грамм у ответа и образца, а также накладывает штраф на короткие ответы. Униграммы измеряют количество совпадающих слов, а более длинные n-граммы - совпадающих цепочек. 
Метрика является вычислительно лёгкой, но обладает большими недостатками: снижение оценки на длинных предложениях и неспособность учитывать смысл слов.
- ROUGE высчитывает не только точность (как BLEU), но и полноту для нахождения F1. Это позволяет определить долю исходной информации, попавшую в ответ - степень охвата важной информации.